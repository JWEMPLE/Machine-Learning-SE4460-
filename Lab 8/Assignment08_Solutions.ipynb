{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can import *ANYTHING* you want here.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # this is just a tool to show a progress bar as your simulations are running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Week 08: Nested Spheres\n",
    "\n",
    "Simulation is an incredibly useful tool in data science.  We can use simulation to evaluate how algorithms perform against ground truth, and how algorithms compare to one another.\n",
    "\n",
    "In this assignment, you will be implementing and extending the nested spheres simulation study found in *Elements of Statistical Learning* page 339. https://web.stanford.edu/~hastie/ElemStatLearn/\n",
    "\n",
    "# Nested Spheres\n",
    "\n",
    "Consider a dataset which contains 10 features $X_1 \\,, X_2 \\,, \\cdots \\,, X_{10}$.  The features are standard independent Gaussian random variables.  That is to say\n",
    "\n",
    "$$ X_j \\sim \\operatorname{Normal}(0,1) \\quad \\forall j = 1 \\dots 10$$\n",
    "\n",
    "We are going to use these features to study a classification problem.  You will have to create the target variable, $Y$ by computing the following rule:\n",
    "\n",
    "$$ Y = \\begin{cases}  1 \\quad \\mbox{ if } \\sum_{j=1}^{10} X^2_j>9.34 \\\\ 0 \\quad  \\mbox{else} \\end{cases}$$\n",
    "\n",
    "# The Simulation Study\n",
    "\n",
    "Follow these steps to complete the assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 ( X / 25 pts )\n",
    "Write a function, `generate_data`, that takes a dataset size N and creates a dataset according to the rule above, returning the feature matrix `X` and the labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N):\n",
    "    # Create feature matrix X and labels y\n",
    "    \n",
    "    # Some logic to prevent some errors\n",
    "    if N<=0:\n",
    "        raise ValueError('N must be a positive integer')\n",
    "    if isinstance(N,float):\n",
    "        N = int(np.floor(N))\n",
    "\n",
    "    # Generate the features to learn from.\n",
    "    # Features are iid standard gaussian, so draw from a multivariable standard normal in which the \n",
    "    # covariance matrix is the identity\n",
    "    X = np.random.normal(0,1,(N,10))\n",
    "\n",
    "    # Calculate the sum to determine if y=0 or y=1\n",
    "    y = (np.sum(X**2, axis=1) > 9.34).astype(int)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 ( X / 25 pts )\n",
    "\n",
    "Write a function `run_simulation` that accepts two numbers, Ntrain and Ntest. It should generate a training set and testing set using your `generate_data` function and then train **four classifiers**. The first should be a bagged decision tree, the second should be a random forest with `max_features=1`, the third should be a random forest with `max_features=3`, and the fourth can be anything you like, for example a random forest with more features or an XGboost model. Use 500 trees in your random forests and the bagged classifier. The function should return the accuracy for each of these models estimated using the training set you generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(Ntrain,Ntest):\n",
    "    # Step 1: \n",
    "    # Generate a training and test data sets of observations according to the description above.  \n",
    "    # Label each of these training examples according to the rule above.\n",
    "    Xtrain, ytrain = generate_data(Ntrain)\n",
    "    Xtest, ytest = generate_data(Ntest)\n",
    "    \n",
    "    # Instantiate Models\n",
    "    bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500)\n",
    "    rf1 = RandomForestClassifier(n_estimators=500, max_features=1)\n",
    "    rf3 = RandomForestClassifier(n_estimators=500, max_features=3)\n",
    "    rf5 = RandomForestClassifier(n_estimators=500, max_features=5)\n",
    "    \n",
    "    # Train a bagged estimator, a random forrest with `max_features=1` and a random forest with `max_features=3`. \n",
    "    # Use 500 trees in your random forests and bagged estimator. Then try your own.\n",
    "    bag.fit(Xtrain, ytrain)\n",
    "    rf1.fit(Xtrain, ytrain)\n",
    "    rf3.fit(Xtrain, ytrain)\n",
    "    rf5.fit(Xtrain, ytrain)\n",
    "    \n",
    "    # Use each model to predict on the testing data.  \n",
    "    bag_pred = bag.predict(Xtest)\n",
    "    rf1_pred = rf1.predict(Xtest)\n",
    "    rf3_pred = rf3.predict(Xtest)\n",
    "    rf5_pred = rf5.predict(Xtest)\n",
    "    \n",
    "    # Record the testing error rate (that is 1 - accuracy).\n",
    "    bag_accuracy = accuracy_score(ytest, bag_pred)\n",
    "    rf_mf1_accuracy = accuracy_score(ytest, rf1_pred)\n",
    "    rf_mf3_accuracy = accuracy_score(ytest, rf3_pred)\n",
    "    my_classifier_accuracy = accuracy_score(ytest, rf5_pred)\n",
    "     \n",
    "    return bag_accuracy, rf_mf1_accuracy, rf_mf3_accuracy, my_classifier_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 ( X / 25 pts )\n",
    "\n",
    "Run 50 simulations using a training set of size 1000 and a test set of size 5000 and record all the results in four vectors, one for each type of model. *You should probably debug your code using smaller training and test set sized first because these will take a while. The full simulation takes 10 minutes on my old 2.8GHz core i5 laptop.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:41<00:00, 12.83s/it]\n"
     ]
    }
   ],
   "source": [
    "Ntrain = 1000\n",
    "Ntest = 5000\n",
    "Nsim = 50\n",
    "bag_acc = []\n",
    "rf1_acc = []\n",
    "rf3_acc = []\n",
    "mine_acc = []\n",
    "for sim in tqdm(range(Nsim)):\n",
    "    # Run simulations, collect data\n",
    "    (bag,rf1,rf3,mine) = run_simulation(Ntrain,Ntest)\n",
    "    bag_acc.append(bag)\n",
    "    rf1_acc.append(rf1)\n",
    "    rf3_acc.append(rf3)\n",
    "    mine_acc.append(mine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (X / 25 pts) \n",
    "Plot the error rates for each model using a boxplot for each one. The four models should be across the x-axis, and the y-axis should be accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the error rates as a box plot by model to complete the assignment.\n",
    "df = pd.DataFrame({'bag': bag_acc, 'rf1': rf1_acc, 'rf3': rf3_acc, 'mine': mine_acc})\n",
    "fig, ax = plt.subplots()\n",
    "df.boxplot(ax = ax, grid = False)\n",
    "ax.axhline(0, color = 'red')\n",
    "ax.set_ylabel('Test accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
